{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 48000\n",
      "Val size: 1000\n",
      "Test size: 1000\n"
     ]
    }
   ],
   "source": [
    "#code for making the model independent of the size/location of the Dataset in the machine. \n",
    "\n",
    "#load the CIFAR-10 Dataset\n",
    "from Util_code.preprocess import get_CIFAR10_datasets\n",
    "train_data, val_data, test_data, mean_image = get_CIFAR10_datasets()\n",
    "print(\"Train size: %i\" % len(train_data))\n",
    "print(\"Val size: %i\" % len(val_data))\n",
    "print(\"Test size: %i\" % len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between the correct and your forward pass:\n",
      "2.0456036364110676e-05\n"
     ]
    }
   ],
   "source": [
    "#code for importing the model from the classifers folder\n",
    "#sanity checking the forward propagration with dummy inputs\n",
    "\n",
    "from Util_code.classifiers.classification_cnn import ClassificationCNN\n",
    "from Util_code.preprocess import rel_error\n",
    "device = 'cpu'\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "#creating a random input \n",
    "X = np.random.randn(2, 3, 5, 5).astype(np.float32)\n",
    "X_tensor = torch.from_numpy(X.copy())\n",
    "inputs = X_tensor.to(device)\n",
    "\n",
    "model = ClassificationCNN(input_dim=(3, 5, 5), num_classes=3)\n",
    "model.to(device)\n",
    "outputs = model.forward(inputs)\n",
    "correct_outputs = np.array([[0.0012621, -0.099135,  0.076110],\n",
    "                            [0.0013608, -0.099130,  0.076120]])\n",
    "\n",
    "# The difference should be very small. We get 1e-5\n",
    "print('Difference between the correct and your forward pass:')\n",
    "print(rel_error(correct_outputs, outputs.cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  cpu\n",
      "START TRAIN.\n",
      "Epoch [1/10], Iteration[2/1] Loss: 2.3014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/balamuruganthambiraja/Documents/dlcv/i2dl/pytorch_project/Util_code/solver.py:82: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  self.train_loss_history.append(loss.data[0])\n",
      "/home/balamuruganthambiraja/Documents/dlcv/i2dl/pytorch_project/Util_code/solver.py:86: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  loss.data[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] TRAIN loss: 2.3014, acc: 0.1300\n",
      "Epoch [1/10] VALID loss: 6.5445, acc: 0.1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/balamuruganthambiraja/Documents/dlcv/i2dl/pytorch_project/Util_code/solver.py:122: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  self.val_loss_history.append(loss_val.data[0])\n",
      "/home/balamuruganthambiraja/Documents/dlcv/i2dl/pytorch_project/Util_code/solver.py:126: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  %(epoch+1, num_epochs, loss.data[0], acc_train))\n",
      "/home/balamuruganthambiraja/Documents/dlcv/i2dl/pytorch_project/Util_code/solver.py:128: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  %(epoch+1, num_epochs, loss_val.data[0], acc_val))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Iteration[2/1] Loss: 5.5314\n",
      "Epoch [2/10] TRAIN loss: 5.5314, acc: 0.1700\n",
      "Epoch [2/10] VALID loss: 3.8645, acc: 0.1020\n",
      "Epoch [3/10], Iteration[2/1] Loss: 3.7226\n",
      "Epoch [3/10] TRAIN loss: 3.7226, acc: 0.1000\n",
      "Epoch [3/10] VALID loss: 3.5870, acc: 0.0620\n",
      "Epoch [4/10], Iteration[2/1] Loss: 3.6386\n",
      "Epoch [4/10] TRAIN loss: 3.6386, acc: 0.0500\n",
      "Epoch [4/10] VALID loss: 3.8711, acc: 0.0930\n",
      "Epoch [5/10], Iteration[2/1] Loss: 3.7026\n",
      "Epoch [5/10] TRAIN loss: 3.7026, acc: 0.1300\n",
      "Epoch [5/10] VALID loss: 3.0103, acc: 0.1000\n",
      "Epoch [6/10], Iteration[2/1] Loss: 2.9274\n",
      "Epoch [6/10] TRAIN loss: 2.9274, acc: 0.0500\n",
      "Epoch [6/10] VALID loss: 2.6844, acc: 0.1170\n",
      "Epoch [7/10], Iteration[2/1] Loss: 2.4908\n",
      "Epoch [7/10] TRAIN loss: 2.4908, acc: 0.1400\n",
      "Epoch [7/10] VALID loss: 2.5117, acc: 0.1500\n",
      "Epoch [8/10], Iteration[2/1] Loss: 2.2709\n",
      "Epoch [8/10] TRAIN loss: 2.2709, acc: 0.2100\n",
      "Epoch [8/10] VALID loss: 2.6053, acc: 0.1680\n",
      "Epoch [9/10], Iteration[2/1] Loss: 2.2627\n",
      "Epoch [9/10] TRAIN loss: 2.2627, acc: 0.2200\n",
      "Epoch [9/10] VALID loss: 2.5531, acc: 0.1710\n",
      "Epoch [10/10], Iteration[2/1] Loss: 2.1765\n",
      "Epoch [10/10] TRAIN loss: 2.1765, acc: 0.2300\n",
      "Epoch [10/10] VALID loss: 2.3949, acc: 0.1770\n",
      "FINISH.\n"
     ]
    }
   ],
   "source": [
    "#code for testing the workflow to check the workflow\n",
    "#solver implementation\n",
    "from Util_code.classifiers.classification_cnn import ClassificationCNN\n",
    "from Util_code.solver import Solver\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "num_train = 100\n",
    "model = ClassificationCNN()\n",
    "Sanity_Sampler = SequentialSampler(range(num_train))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=100,shuffle=False, num_workers=2,sampler=OverfitSampler)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=100,shuffle=False, num_workers=2)\n",
    "model.to('cpu')\n",
    "sanity_Solver = Solver(optim_args={\"lr\": 1e-2})\n",
    "sanity_Solver.train(model, train_loader, val_loader,log_nth=1, num_epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  cpu\n",
      "START TRAIN.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/balamuruganthambiraja/Documents/dlcv/i2dl/pytorch_project/Util_code/solver.py:82: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  self.train_loss_history.append(loss.data[0])\n",
      "/home/balamuruganthambiraja/Documents/dlcv/i2dl/pytorch_project/Util_code/solver.py:86: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  loss.data[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Iteration[100/960] Loss: 2.0478\n",
      "Epoch [1/5], Iteration[200/960] Loss: 1.9212\n",
      "Epoch [1/5], Iteration[300/960] Loss: 1.8345\n",
      "Epoch [1/5], Iteration[400/960] Loss: 1.8719\n",
      "Epoch [1/5], Iteration[500/960] Loss: 1.9451\n",
      "Epoch [1/5], Iteration[600/960] Loss: 1.7407\n",
      "Epoch [1/5], Iteration[700/960] Loss: 1.7498\n",
      "Epoch [1/5], Iteration[800/960] Loss: 1.9345\n",
      "Epoch [1/5], Iteration[900/960] Loss: 1.9415\n",
      "Epoch [1/5] TRAIN loss: 1.7759, acc: 0.3400\n",
      "Epoch [1/5] VALID loss: 1.4465, acc: 0.4160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/balamuruganthambiraja/Documents/dlcv/i2dl/pytorch_project/Util_code/solver.py:122: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  self.val_loss_history.append(loss_val.data[0])\n",
      "/home/balamuruganthambiraja/Documents/dlcv/i2dl/pytorch_project/Util_code/solver.py:126: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  %(epoch+1, num_epochs, loss.data[0], acc_train))\n",
      "/home/balamuruganthambiraja/Documents/dlcv/i2dl/pytorch_project/Util_code/solver.py:128: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  %(epoch+1, num_epochs, loss_val.data[0], acc_val))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Iteration[100/960] Loss: 1.9161\n",
      "Epoch [2/5], Iteration[200/960] Loss: 1.7949\n",
      "Epoch [2/5], Iteration[300/960] Loss: 1.3975\n",
      "Epoch [2/5], Iteration[400/960] Loss: 1.7721\n",
      "Epoch [2/5], Iteration[500/960] Loss: 1.8160\n",
      "Epoch [2/5], Iteration[600/960] Loss: 1.6472\n",
      "Epoch [2/5], Iteration[700/960] Loss: 1.6344\n",
      "Epoch [2/5], Iteration[800/960] Loss: 1.5505\n",
      "Epoch [2/5], Iteration[900/960] Loss: 1.7140\n",
      "Epoch [2/5] TRAIN loss: 1.5862, acc: 0.4000\n",
      "Epoch [2/5] VALID loss: 1.3863, acc: 0.4470\n",
      "Epoch [3/5], Iteration[100/960] Loss: 1.7920\n",
      "Epoch [3/5], Iteration[200/960] Loss: 1.6732\n",
      "Epoch [3/5], Iteration[300/960] Loss: 1.4466\n",
      "Epoch [3/5], Iteration[400/960] Loss: 1.5249\n",
      "Epoch [3/5], Iteration[500/960] Loss: 1.5480\n",
      "Epoch [3/5], Iteration[600/960] Loss: 1.6502\n",
      "Epoch [3/5], Iteration[700/960] Loss: 1.5570\n",
      "Epoch [3/5], Iteration[800/960] Loss: 1.4846\n",
      "Epoch [3/5], Iteration[900/960] Loss: 1.4379\n",
      "Epoch [3/5] TRAIN loss: 1.3558, acc: 0.5800\n",
      "Epoch [3/5] VALID loss: 1.3329, acc: 0.4640\n",
      "Epoch [4/5], Iteration[100/960] Loss: 1.4937\n",
      "Epoch [4/5], Iteration[200/960] Loss: 1.7413\n",
      "Epoch [4/5], Iteration[300/960] Loss: 1.4372\n",
      "Epoch [4/5], Iteration[400/960] Loss: 1.5601\n",
      "Epoch [4/5], Iteration[500/960] Loss: 1.2423\n",
      "Epoch [4/5], Iteration[600/960] Loss: 1.4228\n",
      "Epoch [4/5], Iteration[700/960] Loss: 1.5333\n",
      "Epoch [4/5], Iteration[800/960] Loss: 1.6551\n",
      "Epoch [4/5], Iteration[900/960] Loss: 1.7252\n",
      "Epoch [4/5] TRAIN loss: 1.7211, acc: 0.4000\n",
      "Epoch [4/5] VALID loss: 1.2592, acc: 0.4890\n",
      "Epoch [5/5], Iteration[100/960] Loss: 1.6807\n",
      "Epoch [5/5], Iteration[200/960] Loss: 1.3384\n",
      "Epoch [5/5], Iteration[300/960] Loss: 1.5310\n",
      "Epoch [5/5], Iteration[400/960] Loss: 1.5180\n",
      "Epoch [5/5], Iteration[500/960] Loss: 1.5881\n",
      "Epoch [5/5], Iteration[600/960] Loss: 1.2373\n",
      "Epoch [5/5], Iteration[700/960] Loss: 1.5897\n",
      "Epoch [5/5], Iteration[800/960] Loss: 1.1967\n",
      "Epoch [5/5], Iteration[900/960] Loss: 1.5667\n",
      "Epoch [5/5] TRAIN loss: 1.2836, acc: 0.5800\n",
      "Epoch [5/5] VALID loss: 1.2177, acc: 0.5080\n",
      "FINISH.\n",
      "-------------------------------------------------------\n",
      "lr: 0.0001, wd: 0.0000, hd: 100.0000 accuracy: 0.5080\n",
      "BEST Accuracy: 0.5080\n"
     ]
    }
   ],
   "source": [
    "#code for training and validating the network\n",
    "#in order the switch between multiplenetworks,we just need to import it and call the function\n",
    "from Util_code.classifiers.classification_cnn import ClassificationCNN\n",
    "from Util_code.solver import Solver\n",
    "from datetime import datetime\n",
    "log_name = datetime.now().strftime('model'+'_%d-%m-%Y_%H:%M.log')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=50, shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=50, shuffle=False, num_workers=4)\n",
    "\n",
    "best_model = None\n",
    "best_accuracy =  0\n",
    "learning_rates = [1e-4] # 1e-2, 1e-3]\n",
    "weight_decays = [0.0] #, 0.2, 0.4, 0.6]\n",
    "hidden_dims = [100] #, 250, 500, 1000]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for wd in weight_decays:#\n",
    "        for hd in hidden_dims:\n",
    "            acc_it = -1\n",
    "            Model = ClassificationCNN(hidden_dim=hd)\n",
    "            curr_Solver = Solver(optim_args={\"lr\": lr, \"weight_decay\": wd})\n",
    "            curr_Solver.train(Model, train_loader, val_loader, log_nth=100, num_epochs=5)\n",
    "            accuracy = curr_Solver.val_acc_history[-1]\n",
    "            if accuracy > acc_it:\n",
    "                acc_it = accuracy\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_model = Model\n",
    "    \n",
    "            print('-------------------------------------------------------')\n",
    "            print('lr: %.4f, wd: %.4f, hd: %.4f accuracy: %.4f' %(lr, wd, hd, acc_it))\n",
    "    \n",
    "print('BEST Accuracy: %.4f' %(best_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model... models/classification_cnn.model\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'Util_code.classifiers.classification_cnn.ClassificationCNN'>: it's not the same object as Util_code.classifiers.classification_cnn.ClassificationCNN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ff3bb1c785d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#code for saving the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/classification_cnn.model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/balamuruganthambiraja/Documents/dlcv/i2dl/pytorch_project/Util_code/classifiers/classification_cnn.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[1;32m     98\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saving model... %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/balamuruganthambiraja/Documents/dlcv/dl_exe/.venv/lib/python3.5/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \"\"\"\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/balamuruganthambiraja/Documents/dlcv/dl_exe/.venv/lib/python3.5/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/balamuruganthambiraja/Documents/dlcv/dl_exe/.venv/lib/python3.5/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \"\"\"\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/balamuruganthambiraja/Documents/dlcv/dl_exe/.venv/lib/python3.5/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_storages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class 'Util_code.classifiers.classification_cnn.ClassificationCNN'>: it's not the same object as Util_code.classifiers.classification_cnn.ClassificationCNN"
     ]
    }
   ],
   "source": [
    "#code for saving the model\n",
    "Model.save(\"models/classification_cnn.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
